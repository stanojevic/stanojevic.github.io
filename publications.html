<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
  "http://www.w3.org/TR/html4/strict.dtd">

<html>

<head>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<meta name="keywords" content="UvA, PhD, Milos, Stanojevic">
<title>
Miloš Stanojević -- Publications
</title>


<style>
header {
    background-color:#3366CC;
    color:white;
    text-align:center; 
}
nav {
    line-height:30px;
    background-color:#eeeeee;
    height:300px;
    /*width:100px;*/
    width:10%;
    float:left;
    padding:5px;	      
}
photo {
    line-height:30px;
    background-color:#eeeeee;
    /*height:300px;*/
    /*width:700px;*/
    width:35%;
    float:right;
}
section {
    width:50%;
    /*width:700px;*/
    float:left;
    padding:10px;	 	 
}
footer {
    background-color:black;
    color:white;
    clear:both;
    text-align:center;
    padding:5px;	 	 
}
</style>


</head>

<body>


<header>
 <table style="width:100%">
  <tr>
    <td style="width:30%"></td>
    <td style="width:40%"><h1>Miloš Stanojević</h1></td>
    <td style="width:30%"><!--img height="100" src="https://staff.fnwi.uva.nl/m.stanojevic/photo2.jpg"/--></td>
  </tr>
</table> 
</header>

<photo>
	<img style="width:100%" src="./photo2.jpg"/>
</photo>

<nav>
<a href="./index.html"> Home </a><br>
<a href="./publications.html"> Publications </a><br>
<a href="./software.html"> Software </a><br>
<a href="./CV.html"> CV </a><br>
<a href="./Contact.html"> Contact </a><br>
</nav>

<section>

<script>
function copy(dest, source) {
if(dest.source == source) {
dest.innerHTML = "";
dest.source = null;
}
else {
dest.innerHTML = source.innerHTML;
dest.source = source;
}
dest.blur();
}
</script>


Papers:

<p>
2019
</p>

<!-- NAACL19 -->

<ul>
<div id="naacl19_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{NAACL2019:CCG,
  author = "Milo\v{s} Stanojevi\'{c} and Mark Steedman",
  title = "CCG Parsing Algorithm with Incremental Tree Rotation",
  booktitle = "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics, Volume 1 (Long Papers)",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  location = "Minneapolis, Minnesota"
}
    </pre>
    </blockquote>
</div>
<div id="naacl19_text" style="display:none">
    <blockquote>
The main obstacle to incremental sentence processing arises from
right-branching constituent structures, which are present in the
majority of English sentences, as well as optional constituents that
adjoin on the right, such as right adjuncts and right conjuncts. In
CCG, many right-branching derivations can be replaced by semantically
equivalent left-branching incremental derivations.

The problem of right-adjunction is more resistant to solution,
and has been tackled in the past using revealing-based
approaches that often rely either on the higher-order unification over
lambda terms (Pareschi and Steedman,1987) or heuristics over dependency
representations that do not cover the whole CCGbank (Ambati et al., 2015).

We propose a new incremental parsing algorithm for CCG following
the same revealing tradition of work but having a purely syntactic
approach that does not depend on access to a distinct level of
semantic representation. This algorithm can cover the whole CCGbank,
with greater incrementality and accuracy than previous
proposals.
</div>
    <li> 
    <!--a href=""--><b>CCG Parsing Algorithm with Incremental Tree Rotation</b><!--/a--> <br/>
      Miloš Stanojević and Mark Steedman<br/>
      <CITE> NAACL </CITE> 2019.<br/>
        <a   href="javascript:copy(naacl19,naacl19_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(naacl19, naacl19_bib)">bib</a>&nbsp;&nbsp;
    <!--a href=""-->pdf<!--/a-->&nbsp;&nbsp;  
    <a href="https://github.com/stanojevic/rotating-ccg">code</a>&nbsp;&nbsp;  
    <br>
    <div id="naacl19"></div>
     </li><p><p>
 
 </ul>

<p>
2018
</p>

<!-- CogACLL18 -->

<ul>
<div id="cogacll18_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic:stabler:2018:cogacll,
  author = 	"Stanojevi{\'{c}}, Milo{\v{s}}
		and Stabler, Edward",
  title = 	"A Sound and Complete Left-Corner Parsing for Minimalist Grammars",
  booktitle = 	"Proceedings of the Eight Workshop on Cognitive Aspects of Computational Language Learning and Processing",
  year = 	"2018",
  publisher = 	"Association for Computational Linguistics",
  pages = 	"65--74",
  location = 	"Melbourne",
  url = 	"http://aclweb.org/anthology/W18-2809"
}
    </pre>
    </blockquote>
</div>
<div id="cogacll18_text" style="display:none">
    <blockquote>
	    This paper presents a left-corner parser for
minimalist grammars.  The relation between the parser and the grammar is transparent in the sense that there is a very simple 1-1 correspondence between derivations and parses. Like left-corner context-free parsers, left-corner minimalist parsers can be non-terminating when the grammar has empty left corners, so an easily computed left-corner oracle is defined to restrict the search.
</div>
    <li> 

    <a href="http://www.aclweb.org/anthology/W18-2809"><b>A Sound and Complete Left-Corner Parsing for Minimalist Grammars</b></a> <br/>
      Miloš Stanojević and Edward Stabler<br/>
      <CITE> CogACLL </CITE> 2018.<br/>
        <a   href="javascript:copy(cogacll18,cogacll18_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(cogacll18, cogacll18_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.aclweb.org/anthology/W18-2809">pdf</a>&nbsp;&nbsp;  
    <a href="https://github.com/stanojevic/Left-Corner-MG-parser">code</a>&nbsp;&nbsp;  
    <br>
    <div id="cogacll18"></div>
     </li><p><p>
 
 </ul>

<!-- PROPOR18 -->

<ul>
<div id="propor18_bib" style="display:none">
    <blockquote>
        <pre>
@inproceedings{real2018sick,
  title={SICK-BR: a Portuguese corpus for inference},
  author={Real, Livy and Rodrigues, Ana and e Silva, Andressa Vieira and Albiero, Beatriz and Thalenberg, Bruna and Guide, Bruno and Silva, Cindy and de Oliveira Lima, Guilherme and C{\^a}mara, Igor CS and Stanojevi{\'c}, Milo{\v{s}} and others},
  booktitle={International Conference on Computational Processing of the Portuguese Language},
  pages={303--312},
  year={2018},
  organization={Springer}
}
    </pre>
    </blockquote>
</div>
<div id="propor18_text" style="display:none">
    <blockquote>
	    We describe SICK-BR, a Brazilian Portuguese corpus annotated with inference relations and semantic relatedness between pairs of sentences. SICK-BR is a translation and adaptation of the original SICK, a corpus of English sentences used in several semantic evaluations. SICK-BR consists of around 10k sentence pairs annotated for neutral/contradiction/entailment relations and for semantic relatedness, using a 5 point scale. Here we describe the strategies used for the adaptation of SICK, which preserve its original inference and relatedness relation labels in the SICK-BR Portuguese version. We also discuss some issues with the original corpus and how we might deal with them.
</div>
    <li> 

    <a href="https://www.research.ed.ac.uk/portal/files/76132996/SICK_BR_a_Portuguese_corpus_for_inference.pdf"><b>SICK-BR: a Portuguese corpus for inference</b></a> <br/>
     Livy Real, Ana Rodrigues, Andressa Vieira e Silva, Beatriz Albiero, Bruna Thalenberg, Bruno Guide, Cindy Silva, Guilherme de Oliveira Lima, Igor CS Câmara, Miloš Stanojević, Rodrigo Souza, Valeria de Paiva<br/>
      <CITE> PROPOR </CITE> 2018.<br/>
        <a   href="javascript:copy(propor18,propor18_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(propor18, propor18_bib)">bib</a>&nbsp;&nbsp;
    <a href="https://www.research.ed.ac.uk/portal/files/76132996/SICK_BR_a_Portuguese_corpus_for_inference.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="propor18"></div>
     </li><p><p>
 
 </ul>

<p>
2017
</p>
	
<!-- Thesis -->
	
<ul>
<div id="thesis17_bib" style="display:none">
    <blockquote>
        <pre>
@phdthesis{stanojevic:2017:thesis,
  author    = {Milo\v{s} Stanojevi\'{c}},
  title     = {Permutation Forests for Modeling Word Order in Machine Translation},
  year      = {2017},
  school={University of Amsterdam},
}
    </pre>
    </blockquote>
</div>
<div id="thesis17_text" style="display:none">
    <blockquote>
	  In natural language, there is only a limited space for variation in the word order of linguistic productions.
From a linguistic perspective, word order is the result of multiple application of syntactic recursive functions. These syntactic operations produce hierarchical syntactic structures, as well as a string of words that appear in a certain order.
However, different languages are governed by different syntactic rules. Thus, one of the main problems in machine translation is to find the mapping between word order in the source language and word order in the target language. This is often done by a method of syntactic transfer, in which the syntactic tree is recovered from the source sentence, and then transduced so that its form is consistent with the syntactic rules of the target language. <br/>
In this dissertation, I propose an alternative to syntactic transfer that maintains its good properties---namely the compositional and hierarchical structure---but, unlike syntactic transfer, it is directly derived from data without requiring any linguistic annotation. This approach brings two main advantages. First, it allows for applying hierarchical reordering even on languages for which there are no syntactic parsers available.
Second, unlike the trees used in syntactic transfer, which in some cases cannot cover the reordering patterns present in the data, the trees used in this work are built directly over the reordering patterns, so they can cover them by definition.<br/>
I treat reordering as a problem of predicting the permutation of the source words which permutes them into an order that is as close as possible to the target side order.
This permutation can be recursively decomposed into a hierarchical structure called a permutation tree (PET) (Zhang and Gildea, 2007). In some cases there can be many permutation trees that can generate the same permutation. This set of permutation trees is called permutation forest.
A permutation forest is a richer representation of a permutation because it covers all possible segmentations consistent with the permutation, so modeling permutations over the whole forest is a more promising approach than modeling a single tree.
I apply permutation trees in two sub-tasks of machine translation: word order prediction and word order evaluation. In the word order prediction scenario I propose a probabilistic model that treats both the non-terminals and the bracketing of the sentence as latent variables. In the context of MT evaluation, I propose evaluation metrics that incorporate PETs and use machine learning methods to approximate human judgment of translation quality.

Overall, the permutation tree models proposed here are (i) compositional, (ii) hierarchical and (iii) directly derived from unannotated translation data. Empirically, the models satisfying these three properties have been shown to improve translation quality, and provide better correlation with human judgment when used for evaluation of machine translation output.
</div>
    <li> 

    <a href="https://pure.uva.nl/ws/files/19494854/Thesis.pdf"><b>PhD Thesis: Permutation Forests for Modeling Word Order in Machine Translation</b></a> <br/>
      Miloš Stanojević<br/>
      <CITE> University of Amsterdam </CITE> 2017.<br/>
        <a   href="javascript:copy(thesis17,thesis17_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(thesis17, thesis17_bib)">bib</a>&nbsp;&nbsp;
    <a href="https://pure.uva.nl/ws/files/19494854/Thesis.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="thesis17"></div>
     </li><p><p>
 
 </ul>

	

<!-- EMNLP17 -->

<ul>
<div id="emnlp17_bib" style="display:none">
    <blockquote>
        <pre>
@inproceedings{stanojevic:alhama:2017:emnlp,
  author    = {Milo\v{s} Stanojevi\'{c} and Raquel G. Alhama},
  title     = {Neural Discontinuous Constituency Parsing},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2017, Copenhagen, Denmark, September
               9-11, 2017},
  year      = {2017},
}
    </pre>
    </blockquote>
</div>
<div id="emnlp17_text" style="display:none">
    <blockquote>
	    One of the most pressing issues in discontinuous constituency transition-based parsing is that the relevant information for parsing decisions could be located in any part of the stack or the buffer. In this paper, we propose a solution to this problem by replacing the structured perceptron model with a recursive neural model that computes a global representation of the configuration, therefore allowing even the most remote parts of the configuration to influence the parsing decisions. We also provide a detailed analysis of how this representation should be built out of sub-representations of its core elements (words, trees and stack). Additionally, we investigate how different types of swap oracles influence the results. Our model is the first neural discontinuous constituency parser, and it outperforms all the previously published models on three out of four datasets while on the fourth it obtains second place by a tiny difference.
</div>
    <li> 

    <a href="https://www.aclweb.org/anthology/D17-1174"><b>Neural Discontinuous Constituency Parsing</b></a> <br/>
      Miloš Stanojević and Raquel G. Alhama<br/>
      <CITE> EMNLP </CITE> 2017.<br/>
        <a   href="javascript:copy(emnlp17,emnlp17_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(emnlp17, emnlp17_bib)">bib</a>&nbsp;&nbsp;
    <a href="https://www.aclweb.org/anthology/D17-1174">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="emnlp17"></div>
     </li><p><p>
 
 </ul>


<!-- ACL17 -->

<ul>
<div id="acl17_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic-simaan:2017:Short,
  author    = {Stanojevi\'{c}, Milo\v{s}  and  Sima'an, Khalil},
  title     = {Alternative Objective Functions for Training MT Evaluation Metrics},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = {July},
  year      = {2017},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {20--25},
  abstract  = {MT evaluation metrics are tested for correlation with human judgments either at
	the sentence- or the corpus-level. Trained metrics ignore corpus-level
	judgments and are trained for high sentence-level correlation only. We show
	that training only for one objective (sentence or corpus level), can not only
	harm the performance on the other objective, but it can also be suboptimal for
	the objective being optimized. To this end we present a metric trained for
	corpus-level and show empirical comparison against a metric trained for
	sentence-level exemplifying how their performance may vary per language pair,
	type and level of judgment. Subsequently we propose a model trained to optimize
	both objectives simultaneously and show that it is far more stable than--and on
	average outperforms--both models on both objectives.},
  url       = {http://aclweb.org/anthology/P17-2004}
}
    </pre>
    </blockquote>
</div>
<div id="acl17_text" style="display:none">
    <blockquote>
MT evaluation metrics are tested for correlation with human judgments either at the sentence- or the corpus-level. Trained metrics ignore corpus-level judgments and are trained for high sentence-level correlation only. We show that training only for one objective (sentence or corpus level), can not only harm the performance on the other objective, but it can also be suboptimal for the objective being optimized. To this end we present a metric trained for corpus-level and show empirical comparison against a metric trained for sentence level exemplifying how their performance may vary per language pair, type and level of judgment. Subsequently we propose a model trained to optimize both objectives simultaneously and show that it is far more stable than–and on average outperforms– both models on both objectives.
</div>
    <li> 

    <a href="http://aclweb.org/anthology/P/P17/P17-2004.pdf"><b>Alternative Objective Functions for Training MT Evaluation Metrics</b> </a><br/>
      Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> ACL </CITE> 2017.<br/>
        <a   href="javascript:copy(acl17,acl17_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(acl17, acl17_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://aclweb.org/anthology/P/P17/P17-2004.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="acl17"></div>
     </li><p><p>
 
 </ul>


<p>
2016
</p>

<!-- LACL16 -->

<ul>
<div id="lacl16_bib" style="display:none">
    <blockquote>
        <pre>

@INBOOK{LACLStanojevic2016,
  pages = {273--290},
  title = "{Minimalist Grammar Transition-Based Parsing}",
  publisher = {Springer Berlin Heidelberg},
  year = {2016},
  editor = {Amblard, Maxime and de Groote, Philippe and Pogodalla, Sylvain and
	Retor{\'e}, Christian},
  author = {Stanojevi{\'{c}}, Milo{\v{s}}},
  address = {Berlin, Heidelberg},
  booktitle = {Logical Aspects of Computational Linguistics. Celebrating 20 Years
	of LACL (1996--2016): 9th International Conference, LACL 2016, Nancy,
	France, December 5-7, 2016, Proceedings},
  doi = {10.1007/978-3-662-53826-5_17},
  isbn = {978-3-662-53826-5},
  url = {http://dx.doi.org/10.1007/978-3-662-53826-5_17}
}




    </pre>
    </blockquote>
</div>
<div id="lacl16_text" style="display:none">
    <blockquote>

Current chart-based parsers of Minimalist Grammars exhibit prohibitively
high polynomial complexity that makes them unusable in practice. This paper
presents a transition-based parser for Minimalist Grammars that approximately
searches through the space of possible derivations by means of beam search, and
does so very efficiently: the worst case complexity of building one derivation is
O(n^2 ) and the best case complexity is O(n). This approximated inference can
be guided by a trained probabilistic model that can condition on larger context
than standard chart-based parsers. The transitions of the parser are very similar
to the transitions of bottom-up shift-reduce parsers for Context-Free Grammars,
with additional transitions for online reordering of words during parsing in order
to make non-projective derivations projective.


</div>
    <li> 
    <a href="https://link.springer.com/chapter/10.1007/978-3-662-53826-5_17"><b> Minimalist Grammar Transition-Based Parsing </b></a><br/>
      Miloš Stanojević<br/>
      <CITE> LACL </CITE> 2016.<br/>
        <a   href="javascript:copy(lacl16,lacl16_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(lacl16, lacl16_bib)">bib</a>&nbsp;&nbsp;
    <a href="https://link.springer.com/chapter/10.1007/978-3-662-53826-5_17">pdf</a>&nbsp;&nbsp;  
    <a href="papers/2016_LACL_minimalist_parsing_presentation.pdf">presentation</a>&nbsp;&nbsp;  
    <br>
    <div id="lacl16"></div>
     </li><p><p>
 
 </ul>

<!-- COLING 1 16 -->

<ul>
<div id="coling16_1_bib" style="display:none">
    <blockquote>
        <pre>

@inproceedings{stanojevic-simaan:2016:COLING,
  author    = {Stanojevi\'{c}, Milo\v{s}  and  Sima'an, Khalil},
  year="2016",
  title = 	 "{Hierarchical Permutation Complexity for Word Order Evaluation}",
  booktitle =    {Proceedings of the 26th International Conference on Computational Linguistics (COLING-2016)},
  address   = {Osaka, Japan},
  year = 	 {2016},
  month =        {December},
}



    </pre>
    </blockquote>
</div>
<div id="coling16_1_text" style="display:none">
    <blockquote>

Existing approaches for evaluating word order in machine translation work with metrics computed
directly over a permutation of word positions in system output relative to a reference
translation. However, every permutation factorizes into a permutation tree (PET) built of primal
permutations, i.e., atomic units that do not factorize any further. In this paper we explore
the idea that permutations factorizing into (on average) shorter primal permutations should represent
simpler ordering as well. Consequently, we contribute Permutation Complexity, a class of
metrics over PETs and their extension to forests, and define tight metrics, a sub-class of metrics
implementing this idea. Subsequently we define example tight metrics and empirically test them
in word order evaluation. Experiments on the WMT13 data sets for ten language pairs show that
a tight metric is more often than not better than the baselines.


</div>
    <li> 
    <a href="https://aclweb.org/anthology/C/C16/C16-1204.pdf"> <b> Hierarchical Permutation Complexity for Word Order Evaluation</b> </a><br/>
      Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> COLING </CITE> 2016.<br/>
        <a   href="javascript:copy(coling16_1,coling16_1_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(coling16_1, coling16_1_bib)">bib</a>&nbsp;&nbsp;
    <a href="https://aclweb.org/anthology/C/C16/C16-1204.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="coling16_1"></div>
     </li><p><p>
 
 </ul>


<!-- COLING 2 16 -->

<ul>
<div id="coling16_2_bib" style="display:none">
    <blockquote>
        <pre>

@inproceedings{daiber-stanojevic-simaan:2016:COLING,
  author    = {Daiber, Joachim  and  Stanojevi\'{c}, Milo\v{s}  and  Sima'an, Khalil},
  year="2016",
  title = 	 "{Universal Reordering via Linguistic Typology}",
  booktitle =    {Proceedings of the 26th International Conference on Computational Linguistics (COLING-2016)},
  address   = {Osaka, Japan},
  year = 	 {2016},
  month =        {December},
}



    </pre>
    </blockquote>
</div>
<div id="coling16_2_text" style="display:none">
    <blockquote>

In this paper we explore the novel idea of building a single universal reordering model from English
to a large number of target languages. To build this model we exploit typological features
of word order for a large number of target languages together with source (English) syntactic
features and we train this model on a single combined parallel corpus representing all (22) involved
language pairs. We contribute experimental evidence for the usefulness of linguistically
defined typological features for building such a model. When the universal reordering model is
used for preordering followed by monotone translation (no reordering inside the decoder), our
experiments show that this pipeline gives comparable or improved translation performance with
a phrase-based baseline for a large number of language pairs (12 out of 22) from diverse language
families.


</div>
    <li> 
    <a href="http://www.aclweb.org/anthology/C/C16/C16-1298.pdf"> <b> Universal Reordering via Linguistic Typology </b> </a><br/>
      Joachim Daiber, Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> COLING </CITE> 2016.<br/>
        <a   href="javascript:copy(coling16_2,coling16_2_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(coling16_2, coling16_2_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.aclweb.org/anthology/C/C16/C16-1298.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="coling16_2"></div>
     </li><p><p>
 
 </ul>

<!-- WMT16 preordering -->

<ul>
<div id="wmt16_preordering_bib" style="display:none">
    <blockquote>
        <pre>

@InProceedings{daiber-EtAl:2016:WMT,
  author    = {Daiber, Joachim  and  Stanojevi\'{c}, Milo\v{s}  and  Aziz, Wilker  and  Sima'an, Khalil},
  title     = {Examining the Relationship between Preordering and Word Order Freedom in Machine Translation},
  booktitle = {Proceedings of the First Conference on Machine Translation},
  month     = {August},
  year      = {2016},
  address   = {Berlin, Germany},
  publisher = {Association for Computational Linguistics},
  pages     = {118--130},
  url       = {http://www.aclweb.org/anthology/W/W16/W16-2213}
}

    </pre>
    </blockquote>
</div>
<div id="wmt16_preordering_text" style="display:none">
    <blockquote>

We study the relationship between word
order freedom and preordering in statistical
machine translation. To assess word
order freedom, we first introduce a novel
entropy measure which quantifies how difficult it is to predict word order given a
source sentence and its syntactic analysis.
We then address preordering for two target
languages at the far ends of the word order
freedom spectrum, German and Japanese,
and argue that for languages with more
word order freedom, attempting to predict
a unique word order given source clues
only is less justified. Subsequently, we examine
lattices of n-best word order predictions
as a unified representation for languages
from across this broad spectrum
and present an effective solution to a resulting
technical issue, namely how to select
a suitable source word order from
the lattice during training. Our experiments
show that lattices are crucial for
good empirical performance for languages
with freer word order (English–German)
and can provide additional improvements
for fixed word order languages (English–Japanese).

</div>
    <li> 
    <a href="http://www.statmt.org/wmt16/pdf/W16-2213.pdf"> <b> Examining the Relationship between Preordering and Word Order Freedom in Machine Translation </b> </a><br/>
      Joachim Daiber, Miloš Stanojević, Wilker Aziz, Khalil Sima'an<br/>
      <CITE> WMT </CITE> 2016.<br/>
        <a   href="javascript:copy(wmt16_preordering,wmt16_preordering_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(wmt16_preordering, wmt16_preordering_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.statmt.org/wmt16/pdf/W16-2213.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="wmt16_preordering"></div>
     </li><p><p>
 
 </ul>

<!-- WMT16 metrics -->

<ul>
<div id="wmt16_metrics_bib" style="display:none">
    <blockquote>
        <pre>

@InProceedings{bojar-EtAl:2016:WMT2,
  author    = {Bojar, Ond\v{r}ej  and  Graham, Yvette  and  Kamran, Amir  and  Stanojevi\'{c}, Milo\v{s}},
  title     = {Results of the WMT16 Metrics Shared Task},
  booktitle = {Proceedings of the First Conference on Machine Translation},
  month     = {August},
  year      = {2016},
  address   = {Berlin, Germany},
  publisher = {Association for Computational Linguistics},
  pages     = {199--231},
  url       = {http://www.aclweb.org/anthology/W/W16/W16-2302}
}


    </pre>
    </blockquote>
</div>
<div id="wmt16_metrics_text" style="display:none">
    <blockquote>

This paper presents the results of the
WMT16 Metrics Shared Task. We asked
participants of this task to score the outputs
of the MT systems involved in the
WMT16 Shared Translation Task. We
collected scores of 16 metrics from 9 research
groups. In addition to that, we computed
scores of 9 standard metrics (BLEU,
SentBLEU, NIST, WER, PER, TER and
CDER) as baselines. The collected scores
were evaluated in terms of system-level
correlation (how well each metric’s scores
correlate with WMT16 official manual
ranking of systems) and in terms of segment
level correlation (how often a metric
agrees with humans in comparing two
translations of a particular sentence).
This year there are several additions to
the setup: large number of language pairs
(18 in total), datasets from different domains
(news, IT and medical), and different
kinds of judgments: relative ranking
(RR), direct assessment (DA) and HUME
manual semantic judgments. Finally, generation
of large number of hybrid systems
was trialed for provision of more conclusive
system-level metric rankings.

</div>
    <li> 
    <a href="http://www.statmt.org/wmt16/pdf/W16-2302.pdf"> <b> Results of the WMT16 Metrics Shared Task </b> </a><br/>
      Ondřej Bojar, Yvette Graham, Amir Kamran and Miloš Stanojević<br/>
      <CITE> WMT </CITE> 2016.<br/>
        <a   href="javascript:copy(wmt16_metrics,wmt16_metrics_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(wmt16_metrics, wmt16_metrics_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.statmt.org/wmt16/pdf/W16-2302.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="wmt16_metrics"></div>
     </li><p><p>
 
 </ul>

<!-- WMT16 tuning -->

<ul>
<div id="wmt16_tuning_bib" style="display:none">
    <blockquote>
        <pre>

@InProceedings{jawaid-EtAl:2016:WMT,
  author    = {Jawaid, Bushra  and  Kamran, Amir  and  Stanojevi\'{c}, Milo\v{s}  and  Bojar, Ond\v{r}ej},
  title     = {Results of the WMT16 Tuning Shared Task},
  booktitle = {Proceedings of the First Conference on Machine Translation},
  month     = {August},
  year      = {2016},
  address   = {Berlin, Germany},
  publisher = {Association for Computational Linguistics},
  pages     = {232--238},
  url       = {http://www.aclweb.org/anthology/W/W16/W16-2303}
}


    </pre>
    </blockquote>
</div>
<div id="wmt16_tuning_text" style="display:none">
    <blockquote>

This paper presents the results of the
WMT16 Tuning Shared Task. We provided
the participants of this task with a
complete machine translation system and
asked them to tune its internal parameters
(feature weights). The tuned systems were
used to translate the test set and the outputs
were manually ranked for translation
quality. We received 4 submissions in the
Czech-English and 8 in the English-Czech
translation direction. In addition, we ran
2 baseline setups, tuning the parameters
with standard optimizers for BLEU score.
In contrast to previous years, the tuned
systems in 2016 rely on large data.

</div>
    <li> 
    <a href="http://www.statmt.org/wmt16/pdf/W16-2302.pdf"> <b> Results of the WMT16 Tuning Shared Task </b> </a><br/>
      Bushra Jawaid, Amir Kamran, Miloš Stanojević and Ondřej Bojar<br/>
      <CITE> WMT </CITE> 2016.<br/>
        <a   href="javascript:copy(wmt16_tuning,wmt16_tuning_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(wmt16_tuning, wmt16_tuning_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.statmt.org/wmt16/pdf/W16-2302.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="wmt16_tuning"></div>
     </li><p><p>
 
 </ul>

<p>
2015
</p>


<!-- EMNLP15 -->

<ul>
<div id="emnlp15_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic-simaan:2015:EMNLP,
  author    = {Stanojevi\'{c}, Milo\v{s}  and  Sima'an, Khalil},
  title     = "{Reordering Grammar Induction}",
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  pages     = {44--54},
  url       = {http://aclweb.org/anthology/D15-1005}
}


    </pre>
    </blockquote>
</div>

<div id="emnlp15_text" style="display:none">
    <blockquote>
We present a novel approach for unsupervised induction of a Reordering Gram-
mar using a modified form of permutation trees (Zhang and Gildea, 2007), which
we apply to preordering in phrase-based
machine translation. Unlike previous approaches, we induce in one step both the
hierarchical structure and the transduction
function over it from word-aligned parallel
corpora. Furthermore, our model (1) handles non-ITG reordering patterns (up to
5-ary branching), (2) is learned from all
derivations by treating not only labeling
but also bracketing as latent variable, (3) is
entirely unlexicalized at the level of reordering rules, and (4) requires no linguis-
tic annotation.
Our model is evaluated both for accuracy
in predicting target order, and for its impact on translation quality. We report sig-
nificant performance gains over phrase reordering, and over two known preordering
baselines for English-Japanese.

</div>
    <li> 
    <a href="http://www.aclweb.org/anthology/D15-1005"> <b> Reordering Grammar Induction </b> </a><br/>
      Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> EMNLP </CITE> 2015.<br/>
        <a   href="javascript:copy(emnlp15,emnlp15_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(emnlp15, emnlp15_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.aclweb.org/anthology/D15-1005">pdf</a>&nbsp;&nbsp;  
    <a href="https://vimeo.com/154053492">video</a>&nbsp;&nbsp;  
    <br>
    <div id="emnlp15"></div>
     </li><p><p>
 
 </ul>

<!-- WMT15 BEER -->
<ul>
<div id="wmt15_beer_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic-simaan:2015:WMT,
  author    = {Stanojevi\'{c}, Milo\v{s}  and  Sima'an, Khalil},
  title     = "{BEER 1.1: ILLC UvA submission to metrics and tuning task}",
  booktitle = {Proceedings of the Tenth Workshop on Statistical Machine Translation},
  month     = {September},
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  pages     = {396--401},
  url       = {http://aclweb.org/anthology/W15-3050}
}


    </pre>
    </blockquote>
</div>

<div id="wmt15_beer_text" style="display:none">
    <blockquote>
We describe the submissions of ILLC
UvA to the metrics and tuning tasks on
WMT15. Both submissions are based
on the BEER evaluation metric originally presented on WMT14 (Stanojević
and Sima’an, 2014a). The main changes
introduced this year are: (i) extending
the learning-to-rank trained sentence level
metric to the corpus level (but still decomposable to sentence level), (ii) incorporating syntactic ingredients based on dependency trees, and (iii) a technique for finding parameters of BEER that avoid “gaming of the metric” during tuning.

</div>
    <li> 
    <a href="http://www.statmt.org/wmt15/pdf/WMT50.pdf"> <b> BEER 1.1: ILLC UvA submission to metrics and tuning task </b> </a><br/>
      Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> WMT </CITE> 2015.<br/>
        <a   href="javascript:copy(wmt15_beer,wmt15_beer_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(wmt15_beer, wmt15_beer_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.statmt.org/wmt15/pdf/WMT50.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="wmt15_beer"></div>
     </li><p><p>
 
 </ul>


<!-- WMT15 Metrics Task -->
<ul>
<div id="wmt15_metrics_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic-EtAl:2015:WMT,
  author    = {Stanojevi\'{c}, Milo\v{s}  and  Kamran, Amir  and  Koehn, Philipp  and  Bojar, Ond\v{r}ej},
  title     = "{Results of the WMT15 Metrics Shared Task}",
  booktitle = {Proceedings of the Tenth Workshop on Statistical Machine Translation},
  month     = {September},
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  pages     = {256--273},
  url       = {http://aclweb.org/anthology/W15-3031}
}


    </pre>
    </blockquote>
</div>

<div id="wmt15_metrics_text" style="display:none">
    <blockquote>
This paper presents the results of the
WMT15 Metrics Shared Task. We asked
participants of this task to score the outputs of the MT systems involved in the
WMT15 Shared Translation Task. We collected scores of 46 metrics from 11 research groups. In addition to that, we
computed scores of 7 standard metrics
(BLEU, SentBLEU, NIST, WER, PER,
TER and CDER) as baselines. The collected scores were evaluated in terms of
system level correlation (how well each
metric’s scores correlate with WMT15 official manual ranking of systems) and in
terms of segment level correlation (how
often a metric agrees with humans in comparing two translations of a particular sentence).

</div>
    <li> 
    <a href="http://aclweb.org/anthology/W15-3031.pdf"> <b> Results of the WMT15 Metrics Shared Task </b></a><br/>
      Miloš Stanojević, Amir Kamran, Philipp Koehn and Ondřej Bojar<br/>
      <CITE> WMT </CITE> 2015.<br/>
        <a   href="javascript:copy(wmt15_metrics,wmt15_metrics_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(wmt15_metrics, wmt15_metrics_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://aclweb.org/anthology/W15-3031.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="wmt15_metrics"></div>
     </li><p><p>
 
 </ul>


<!-- WMT15 Tuning Task -->
<ul>
<div id="wmt15_tuning_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic-kamran-bojar:2015:WMT,
  author    = {Stanojevi\'{c}, Milo\v{s}  and  Kamran, Amir  and  Bojar, Ond\v{r}ej},
  title     = "{Results of the WMT15 Tuning Shared Task}",
  booktitle = {Proceedings of the Tenth Workshop on Statistical Machine Translation},
  month     = {September},
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  pages     = {274--281},
  url       = {http://aclweb.org/anthology/W15-3032}
}

    </pre>
    </blockquote>
</div>

<div id="wmt15_tuning_text" style="display:none">
    <blockquote>
This paper presents the results of the
WMT15 Tuning Shared Task. We provided the participants of this task with a
complete machine translation system and
asked them to tune its internal parameters
(feature weights). The tuned systems were
used to translate the test set and the outputs were manually ranked for translation
quality. We received 4 submissions in the
English-Czech and 6 in the Czech-English
translation direction. In addition, we ran
3 baseline setups, tuning the parameters
with standard optimizers for BLEU score.

</div>
    <li> 
    <a href="http://www.statmt.org/wmt15/pdf/WMT32.pdf"> <b> Results of the WMT15 Tuning Shared Task </b> </a><br/>
      Miloš Stanojević, Amir Kamran and Ondřej Bojar<br/>
      <CITE> WMT </CITE> 2015.<br/>
        <a   href="javascript:copy(wmt15_tuning,wmt15_tuning_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(wmt15_tuning, wmt15_tuning_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.statmt.org/wmt15/pdf/WMT32.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="wmt15_tuning"></div>
     </li><p><p>
 
 </ul>

<!-- MT Marathon talk 2015 -->

<ul>

    <li> 
    <a href="http://ufal.mff.cuni.cz/mtm15//programme.html"> <b> Discriminative Training lecture at Machine Translation Marathon </b> </a><br/>
      Miloš Stanojević<br/>
      <CITE> Machine Translation Marathon </CITE> 2015.<br/>
    <a href=http://ufal.mff.cuni.cz/mtm15//files/10-discriminative-training-milos-stanojevic.pdf>  slides  </a>&nbsp;&nbsp;
    <a href=http://lectures.ms.mff.cuni.cz/view.php?rec=277>  video  </a>
    <br>
    <div id="wmt15_mtm"></div>
     </li><p><p>
 
 </ul>

<!-- PBML15 -->
<ul>
<div id="pbml15_bib" style="display:none">
    <blockquote>
        <pre>
@article{stanojevic-simaan:2015:PBML,
  title="{Evaluating MT systems with BEER}",
  author={Stanojevi\'{c}, Milo\v{s} and Sima'an, Khalil},
  journal={The Prague Bulletin of Mathematical Linguistics},
  volume={104},
  pages={17--26},
  year={2015}
}
    </pre>
    </blockquote>
</div>

<div id="pbml15_text" style="display:none">
    <blockquote>
We present BEER, an open source implementation of a machine translation evaluation metric. BEER is a metric trained for high correlation with human ranking by using learning-to-rank training methods. For evaluation of lexical accuracy it uses sub-word units(character n-grams) while for measuring word order it uses hierarchical representations based on PETs (permutation trees). During the last WMT metrics tasks, BEER has shown high correlation with human judgments both on the sentence and the corpus levels. In this paper we will show how BEER can be used for (i) full evaluation of MT output, (ii) isolated evaluation of word order and (iii) tuning MT systems.

</div>
    <li> 
    <a href="https://ufal.mff.cuni.cz/pbml/104/art-stanojevic-simaan.pdf"> <b> Evaluating MT systems with BEER </b> </a><br/>
      Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> PBML </CITE> 2015.<br/>
        <a   href="javascript:copy(pbml15,pbml15_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(pbml15, pbml15_bib)">bib</a>&nbsp;&nbsp;
    <a href="https://ufal.mff.cuni.cz/pbml/104/art-stanojevic-simaan.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="pbml15"></div>
     </li><p><p>
 
 </ul>

<p>
2014
</p>

<!-- EMNLP14 -->
<ul>
<div id="emnlp14_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic-simaan:2014:EMNLP2014,
  author    = {Stanojevi\'{c}, Milo\v{s}  and  Sima'an, Khalil},
  title     = "{Fitting Sentence Level Translation Evaluation with Many Dense Features}",
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = {October},
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  pages     = {202--206},
  url       = {http://www.aclweb.org/anthology/D14-1025}
}

    </pre>
    </blockquote>
</div>

<div id="emnlp14_text" style="display:none">
    <blockquote>
Sentence level evaluation in MT has turned out far more difficult than corpus level evaluation. Existing sentence level metrics employ a limited set of features, most of which are rather sparse at the sentence level, and their intricate models are rarely trained for ranking. This paper presents a simple linear model exploiting 33 relatively dense features, some of which are novel while others are known but seldom used, and train it under the learning-to-rank framework. We evaluate our metric on the standard WMT12 data showing that it outperforms the strong baseline METEOR. We also analyze the contribution of individual features and the choice of training data, language-pair vs. target-language data, providing new insights into this task.
</div>
    <li> 
    <a href="http://emnlp2014.org/papers/pdf/EMNLP2014025.pdf"> <b> Fitting Sentence Level Translation Evaluation with Many Dense Features </b> </a><br/>
      Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> EMNLP </CITE> 2014.<br/>
        <a   href="javascript:copy(emnlp14,emnlp14_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(emnlp14, emnlp14_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://emnlp2014.org/papers/pdf/EMNLP2014025.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="emnlp14"></div>
     </li><p><p>
 
 </ul>
<!-- SSST14 -->
<ul>
<div id="ssst14_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic-simaan:2014:SSST-8,
  author    = {Stanojevi\'{c}, Milo\v{s}  and  Sima'an, Khalil},
  title     = "{Evaluating Word Order Recursively over Permutation-Forests}",
  booktitle = {Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation},
  month     = {October},
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  pages     = {138--147},
  url       = {http://www.aclweb.org/anthology/W14-4017}
}

    </pre>
    </blockquote>
</div>

<div id="ssst14_text" style="display:none">
    <blockquote>
Automatically evaluating word order of MT system output at the sentence-level is challenging. At the sentence-level, ngram counts are rather sparse which makes it difficult to measure word order quality effectively using lexicalized units. Recent approaches abstract away from lexicalization by assigning a score to the permutation representing how word positions in system output move around relative to a reference translation. Metrics over permutations exist (e.g., Kendal tau or Spearman Rho) and have been shown to be useful in earlier work. However, none of the existing metrics over permutations groups word positions recursively into larger phrase-like blocks, which makes it difficult to account for long-distance reordering phenomena. In this paper we explore novel metrics computed over Permutation Forests (PEFs), packed charts of Permutation Trees (PETs), which are tree decompositions of a permutation into primitive ordering units. We empirically compare PEFs metric against five known reordering metrics on WMT13 data for ten language pairs. The PEFs metric shows better correlation with human ranking than the other metrics almost on all language pairs. None of the other metrics exhibits as stable behavior across language pairs.
</div>
    <li> 
    <a href="http://www.aclweb.org/anthology/W14-4017"> <b> Evaluating Word Order Recursively over Permutation-Forests </b> </a><br/>
      Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> SSST </CITE> 2014.<br/>
        <a   href="javascript:copy(ssst14,ssst14_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(ssst14, ssst14_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.aclweb.org/anthology/W14-4017">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="ssst14"></div>
     </li><p><p>
 
 </ul>


<!-- WMT14 -->
<ul>
<div id="wmt14_bib" style="display:none">
    <blockquote>
        <pre>
@InProceedings{stanojevic-simaan:2014:WMT,
  author    = {Stanojevi\'{c}, Milo\v{s} and  Sima'an, Khalil},
  title     = "{BEER: BEtter Evaluation as Ranking}",
  booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2014},
  address   = {Baltimore, Maryland, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {414--419},
  url       = {http://www.aclweb.org/anthology/W/W14/W14-3354}
}

    </pre>
    </blockquote>
</div>

<div id="wmt14_text" style="display:none">
    <blockquote>
We present the UvA-ILLC submission of the BEER metric to WMT 14 metrics task.  BEER is a sentence level metric that can incorporate a large number of features combined in a linear model. Novel contributions are (1) efficient tuning of a large number of features for maximizing correlation with human system ranking, and (2) novel features that give smoother sentence level scores.  </blockquote>
</div>
    <li> 
    <a href="http://www.aclweb.org/anthology/W14-3354"> <b> BEER: BEtter Evaluation as Ranking </b> </a><br/>
      Miloš Stanojević and Khalil Sima'an<br/>
      <CITE> WMT </CITE> 2014.<br/>
        <a   href="javascript:copy(wmt14,wmt14_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(wmt14, wmt14_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.aclweb.org/anthology/W14-3354">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="wmt14"></div>
     </li><p><p>
 
 </ul>

<p>
2012
</p>


<!-- WMT14 -->
<ul>
<div id="wmt12_bib" style="display:none">
    <blockquote>
        <pre>
@INPROCEEDINGS{tamchyna2012selecting,
  author = {Tamchyna, Ale{\v{s}} and Galu{\v{s}}{\v{c}}{\'a}kov{\'a}, Petra and Kamran, Amir and Stanojevi{\'c}, Milo{\v{s}} and Bojar, Ond{\v{r}}ej},
  title = "{Selecting data for English-to-Czech machine translation}",
  booktitle = {Proceedings of the Seventh Workshop on Statistical Machine Translation},
  year = {2012},
  pages = {374--381},
  organization = {Association for Computational Linguistics}
}


    </pre>
    </blockquote>
</div>

<div id="wmt12_text" style="display:none">
    <blockquote>
We provide a few insights on data selection for machine translation. We evaluate the quality of the new CzEng 1.0, a parallel data source used in WMT12. We describe a simple technique for reducing out-of-vocabulary rate after phrase extraction. We discuss the benefits of tuning towards multiple reference translations for English-Czech language pair. We introduce a novel approach to data selection by full-text indexing and search: we select sentences similar to the test set from a large monolingual corpus and explore several options of incorporating them in a machine translation system. We show that this method can improve translation quality. Finally, we describe our submitted system CU-TAMCH-BOJ.
  </blockquote>
</div>
    <li> 
    <a href="http://www.statmt.org/wmt12/pdf/WMT48.pdf"> <b> Selecting data for English-to-Czech machine translation </b> </a><br/>
      Aleš Tamchyna, Petra Galuščáková, Amir Kamran, Miloš Stanojević, Ondřej Bojar<br/>
      <CITE> WMT </CITE> 2012.<br/>
        <a   href="javascript:copy(wmt12,wmt12_text)">abstract</a>&nbsp;&nbsp;
    <a  href="javascript:copy(wmt12, wmt12_bib)">bib</a>&nbsp;&nbsp;
    <a href="http://www.statmt.org/wmt12/pdf/WMT48.pdf">pdf</a>&nbsp;&nbsp;  
    <br>
    <div id="wmt12"></div>
     </li><p><p>
 
 </ul>

</section>
</body>

</html>
